# test_ratios_scraper_corrected.py - Test CORRECTO sin login para Screenermatic
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from scraper.web_scraper import WebScraperPlaywright

def test_ratios_scraper_direct():
    """Test del scraper de ratios SIN login - directo a Screenermatic"""
    print("ğŸ§ª TEST DEL SCRAPER DE RATIOS - DIRECTO A SCREENERMATIC")
    print("=" * 60)
    print("ğŸ’¡ Los ratios estÃ¡n en Screenermatic, NO en Balanz")
    print("ğŸ’¡ No necesitamos login para acceder a los ratios")
    print("=" * 60)
    
    # ConfiguraciÃ³n de test
    test_tickers = ['ALUA', 'COME', 'EDN', 'AAPL', 'MSFT']  # Mix de argentinos y US
    
    scraper = WebScraperPlaywright(headless=False)
    
    try:
        # 1. Solo iniciar navegador (SIN LOGIN)
        print("\nğŸ”§ PASO 1: INICIANDO NAVEGADOR")
        print("-" * 30)
        
        scraper.start_browser()
        print("âœ… Navegador iniciado correctamente")
        
        # 2. Crear el scraper directamente (usando el original o el corregido)
        print("\nğŸ“Š PASO 2: PROBANDO SCRAPER DE RATIOS")
        print("-" * 40)
        
        # Primero intentar con el original
        try:
            from financial_ratios_scraper import FinancialRatiosScraper
            print("âœ… Usando financial_ratios_scraper.py original")
            scraper_version = "original"
        except ImportError:
            print("âŒ No se encontrÃ³ financial_ratios_scraper.py original")
            return False
        
        # Si queremos probar la versiÃ³n corregida:
        # try:
        #     from financial_ratios_scraper_fixed import FinancialRatiosScraper
        #     print("âœ… Usando financial_ratios_scraper_fixed.py")
        #     scraper_version = "fixed"
        # except ImportError:
        #     print("âŒ No se encontrÃ³ financial_ratios_scraper_fixed.py")
        #     print("ğŸ’¡ Copia el cÃ³digo del artifact y guÃ¡rdalo como financial_ratios_scraper_fixed.py")
        #     return False
        
        # 3. Crear instancia del scraper de ratios
        ratios_scraper = FinancialRatiosScraper(scraper.page)
        
        print(f"ğŸ” Probando con tickers: {test_tickers}")
        print("â³ Accediendo a Screenermatic...")
        print("â³ Esto puede tomar 30-90 segundos...")
        
        # 4. Ejecutar scraping
        ratios_data = ratios_scraper.get_financial_ratios_for_tickers(test_tickers)
        
        # 5. Analizar resultados
        print("\nğŸ“Š PASO 3: ANALIZANDO RESULTADOS")
        print("-" * 35)
        
        if ratios_data and 'ratios_by_ticker' in ratios_data:
            ratios_by_ticker = ratios_data['ratios_by_ticker']
            success_count = len(ratios_by_ticker)
            total_requested = len(test_tickers)
            
            print(f"âœ… Ã‰XITO: {success_count}/{total_requested} tickers procesados")
            
            # Mostrar resultados detallados
            for ticker, ratios in ratios_by_ticker.items():
                print(f"\nğŸ¯ {ticker}:")
                print(f"   P/E Ratio: {ratios.get('pe', 'N/A')}")
                print(f"   ROE: {ratios.get('roe', 'N/A')}%")
                print(f"   Debt/Equity: {ratios.get('debt_to_equity', 'N/A')}")
                print(f"   Current Ratio: {ratios.get('current_ratio', 'N/A')}")
                print(f"   Score Fundamental: {ratios.get('fundamental_score', 'N/A')}/100")
                print(f"   CategorÃ­a: {ratios.get('valuation_category', 'N/A')}")
            
            # Mostrar metadata del scraping
            print(f"\nğŸ”§ INFO DEL SCRAPING:")
            print(f"   Fuente: {ratios_data.get('data_source', 'N/A')}")
            print(f"   Fecha: {ratios_data.get('fecha', 'N/A')}")
            print(f"   Campos disponibles: {len(ratios_data.get('fields_available', []))}")
            
            # Evaluar Ã©xito
            if success_count >= len(test_tickers) * 0.4:  # Al menos 40% de Ã©xito
                print(f"\nğŸ‰ TEST EXITOSO")
                print(f"âœ… El scraper de ratios funciona correctamente")
                
                if success_count == len(test_tickers):
                    print(f"ğŸŒŸ PERFECTO: Todos los tickers encontrados")
                elif success_count >= len(test_tickers) * 0.8:
                    print(f"ğŸ‘ MUY BIEN: MayorÃ­a de tickers encontrados")
                else:
                    print(f"ğŸ‘Œ BIEN: Suficientes tickers para anÃ¡lisis")
                
                return True
            else:
                print(f"\nâš ï¸ TEST PARCIAL")
                print(f"âœ… El scraper funciona pero encontrÃ³ pocos tickers")
                print(f"ğŸ’¡ Puede ser normal si los tickers argentinos no estÃ¡n en Screenermatic")
                return True
                
        else:
            print("âŒ FALLO COMPLETO")
            print("âŒ No se pudieron extraer ratios")
            
            # InformaciÃ³n de debug bÃ¡sica
            if ratios_data:
                print(f"\nğŸ”§ DATOS DEVUELTOS:")
                for key, value in ratios_data.items():
                    if key != 'ratios_by_ticker':
                        print(f"   {key}: {value}")
            
            print(f"\nğŸ’¡ POSIBLES CAUSAS:")
            print(f"   â€¢ Screenermatic cambiÃ³ su estructura HTML")
            print(f"   â€¢ El sitio estÃ¡ bloqueando el scraping")
            print(f"   â€¢ Los tickers no existen en Screenermatic")
            print(f"   â€¢ Problemas de conexiÃ³n a internet")
            
            return False
        
    except Exception as e:
        print(f"\nâŒ ERROR DURANTE EL TEST: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        print("\nğŸ”§ Cerrando navegador...")
        scraper.close()
        print("âœ… Navegador cerrado")

def test_screenermatic_access():
    """Test simple para verificar acceso a Screenermatic"""
    print("ğŸ§ª TEST DE ACCESO A SCREENERMATIC")
    print("=" * 40)
    
    scraper = WebScraperPlaywright(headless=False)
    
    try:
        scraper.start_browser()
        
        # URL directa de Screenermatic
        ratios_url = "https://www.screenermatic.com/general_ratios.php"
        
        print(f"\nğŸŒ Navegando a: {ratios_url}")
        
        # Configurar headers realistas
        scraper.page.set_extra_http_headers({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3'
        })
        
        scraper.page.goto(ratios_url, wait_until='networkidle')
        import time
        time.sleep(5)
        
        # Verificar acceso
        page_title = scraper.page.title()
        page_url = scraper.page.url
        
        print(f"âœ… PÃ¡gina cargada")
        print(f"ğŸ“‹ TÃ­tulo: {page_title}")
        print(f"ğŸ”— URL final: {page_url}")
        
        # Verificar si hay contenido financiero
        page_content = scraper.page.content()
        
        financial_keywords = ['P/E', 'ROE', 'Debt', 'Current', 'ratio', 'AAPL', 'MSFT']
        found_keywords = [kw for kw in financial_keywords if kw.lower() in page_content.lower()]
        
        print(f"\nğŸ“Š Contenido financiero:")
        print(f"   Keywords encontradas: {len(found_keywords)}/{len(financial_keywords)}")
        print(f"   Keywords: {found_keywords}")
        
        # Verificar estructura de tabla
        table_elements = scraper.page.locator('table').all()
        tbody_elements = scraper.page.locator('tbody').all()
        tr_elements = scraper.page.locator('tr').all()
        
        print(f"\nğŸ”§ Estructura HTML:")
        print(f"   Tablas: {len(table_elements)}")
        print(f"   TBodies: {len(tbody_elements)}")
        print(f"   Filas (TR): {len(tr_elements)}")
        
        # Buscar tickers conocidos
        test_tickers = ['AAPL', 'MSFT', 'GOOGL', 'TSLA']
        found_tickers = []
        
        for ticker in test_tickers:
            elements = scraper.page.locator(f'text="{ticker}"').all()
            if len(elements) > 0:
                found_tickers.append(ticker)
        
        print(f"\nğŸ¯ Tickers encontrados:")
        print(f"   {len(found_tickers)}/{len(test_tickers)}: {found_tickers}")
        
        # EvaluaciÃ³n final
        success_indicators = [
            'screener' in page_title.lower(),
            len(found_keywords) >= 3,
            len(tr_elements) >= 50,
            len(found_tickers) >= 2
        ]
        
        success_count = sum(success_indicators)
        
        print(f"\nğŸ“Š EVALUACIÃ“N FINAL:")
        print(f"âœ… TÃ­tulo correcto: {'SÃ­' if success_indicators[0] else 'No'}")
        print(f"âœ… Contenido financiero: {'SÃ­' if success_indicators[1] else 'No'}")
        print(f"âœ… Estructura de tabla: {'SÃ­' if success_indicators[2] else 'No'}")
        print(f"âœ… Tickers encontrados: {'SÃ­' if success_indicators[3] else 'No'}")
        
        if success_count >= 3:
            print(f"\nğŸ‰ SCREENERMATIC ACCESIBLE")
            print(f"âœ… El sitio funciona correctamente")
            print(f"ğŸ’¡ El problema puede estar en el cÃ³digo del scraper")
            return True
        elif success_count >= 2:
            print(f"\nâš ï¸ SCREENERMATIC PARCIALMENTE ACCESIBLE")
            print(f"âœ… El sitio responde pero con limitaciones")
            print(f"ğŸ’¡ Puede funcionar con ajustes en el scraper")
            return True
        else:
            print(f"\nâŒ SCREENERMATIC NO ACCESIBLE")
            print(f"âŒ El sitio no responde o estÃ¡ bloqueando el acceso")
            print(f"ğŸ’¡ Considera usar fuentes alternativas de ratios")
            return False
        
    except Exception as e:
        print(f"\nâŒ ERROR ACCEDIENDO A SCREENERMATIC: {str(e)}")
        return False
    
    finally:
        scraper.close()

def debug_current_scraper():
    """Debug del scraper actual sin modificaciones"""
    print("ğŸ” DEBUG DEL SCRAPER ACTUAL")
    print("=" * 35)
    
    scraper = WebScraperPlaywright(headless=False)
    
    try:
        scraper.start_browser()
        
        # Importar el scraper actual
        from financial_ratios_scraper import FinancialRatiosScraper
        ratios_scraper = FinancialRatiosScraper(scraper.page)
        
        # Probar con un solo ticker para debug detallado
        test_ticker = ['AAPL']
        
        print(f"ğŸ” Debugeando scraper actual con: {test_ticker}")
        
        # Interceptar errores
        try:
            ratios_data = ratios_scraper.get_financial_ratios_for_tickers(test_ticker)
            
            print(f"\nğŸ“Š RESULTADO:")
            if ratios_data:
                print(f"âœ… Datos obtenidos: {ratios_data.keys()}")
                
                if 'ratios_by_ticker' in ratios_data:
                    ratios_by_ticker = ratios_data['ratios_by_ticker']
                    print(f"ğŸ“Š Tickers procesados: {len(ratios_by_ticker)}")
                    
                    for ticker, ratios in ratios_by_ticker.items():
                        print(f"   {ticker}: {list(ratios.keys())}")
                else:
                    print("âŒ No hay 'ratios_by_ticker' en el resultado")
            else:
                print("âŒ No se obtuvieron datos")
                
        except Exception as scraper_error:
            print(f"âŒ ERROR EN SCRAPER: {str(scraper_error)}")
            import traceback
            traceback.print_exc()
        
        return True
        
    except ImportError:
        print("âŒ No se encontrÃ³ financial_ratios_scraper.py")
        print("ğŸ’¡ AsegÃºrate de que el archivo existe en el directorio")
        return False
    
    except Exception as e:
        print(f"âŒ ERROR EN DEBUG: {str(e)}")
        return False
    
    finally:
        scraper.close()

def main():
    """FunciÃ³n principal de testing"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Test del scraper de ratios CORRECTO')
    parser.add_argument('--access', action='store_true', help='Solo probar acceso a Screenermatic')
    parser.add_argument('--debug', action='store_true', help='Debug del scraper actual')
    
    args = parser.parse_args()
    
    if args.access:
        print("ğŸŒ PROBANDO SOLO ACCESO A SCREENERMATIC")
        return test_screenermatic_access()
    elif args.debug:
        print("ğŸ” DEBUGEANDO SCRAPER ACTUAL")
        return debug_current_scraper()
    else:
        return test_ratios_scraper_direct()

if __name__ == "__main__":
    try:
        success = main()
        
        if success:
            print(f"\nğŸ‰ TEST COMPLETADO EXITOSAMENTE")
            print("ğŸ’¡ El scraper de ratios estÃ¡ funcionando")
            print("ğŸ”„ Puedes ejecutar ahora el test de integraciÃ³n completa:")
            print("   python test_integration.py --full")
        else:
            print(f"\nâš ï¸ TEST CON PROBLEMAS")
            print("ğŸ’¡ Opciones para debugging:")
            print("   python test_ratios_scraper_corrected.py --access")
            print("   python test_ratios_scraper_corrected.py --debug")
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Test interrumpido por el usuario")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ Error crÃ­tico: {str(e)}")
        sys.exit(1)